一致性哈希（Consistent hashing）算法是由 MIT 的Karger 等人与1997年在一篇学术论文（《Consistent hashing and random trees: distributed caching protocols for relieving hot spots on the World Wide Web》）中提出来的，用于解决分布式缓存数据分布问题。在传统的哈希算法下，每条缓存数据落在那个节点是通过哈希算法和服务器节点数量计算出来的，一旦服务器节点数量发生增加或者介绍，哈希值需要重新计算，此时几乎所有的数据和服务器节点的对应关系也会随之发生变化，进而会造成绝大多数缓存的失效。一致性哈希算法通过环形结构和虚拟节点的概念，确保了在缓存服务器节点数量发生变化时大部分数据保持原地不动，从而大幅提高了缓存的有效性。下面我们通过例子来解释一致性哈希的原理。

​ 比如有 n 个节点，对于缓存 数据（k，v）具体存在哪个节点往往 hash\(k\) % n 来计算处理，举一个例子如下表所示，一共有个3个节点，hash函数采用 md5 。

| 缓存key | hash\(k\) % n | 服务器节点 |
| :--- | :--- | :--- |
| user\_nick\_rommel | 1 | 192.168.56.101 |
| user\_nick\_pandy | 0 | 192.168.56.100 |
| user\_nick\_sam | 2 | 192.168.56.102 |

> Md5 的计算结果一般是一串32位的16进制字符串，做取模运算时原始数字较长，实际使用时，可以只截取最后4位或者8位使用，因为hash函数具有随机性，当数据量足球大时，截取部分数据也能保证数据的均匀分布。比如 md5\('user\_nick\_rommel'\)，对应字符串为 29e4fd2a0f05bd63343ae2276ca5038e，取最后4位`038e`转成10进制整数在进行取模运算，038e 对应的10进制数为 910，取模计算得 1 \(9102 % 3 = 1\)。

​ 如果此时对缓存服务器进行扩容，添加一个新节点如 192.168.56.103，那么按照上面的计算方式，n 变为4， 得到的结果如下：

| 缓存key | hash\(k\) % n | 服务器节点 |
| :--- | :--- | :--- |
| user\_nick\_rommel | 2 | 192.168.56.102 |
| user\_nick\_pandy | 2 | 192.168.56.102 |
| user\_nick\_sam | 3 | 192.168.56.103 |

​ 从结果中可见，缓存对应关系完全发生改变，比如 user\_nick\_rommel 这个可以，添加节点钱可以从 192.168.56.101 中读到，添加节点后却读不到了，。一般缓存失效时应用程序都会重新从后端服务加载数据（比如数据库），以这种这种方式分配缓存，当缓节点数量发生改变时，会造成大面积的缓存失效，这回造成后端服务瞬间压力上升，压力过大会造成服务不可以用，如果服务出于关键节点，甚至还会引发雪崩效应（TODO）。

​ 在实际应用中，缓存节点由于故障挂掉，或者空间不足而进行扩容，缓存节点的增减是比较常见的事情，但上面传统方式会使服务的不可靠，下面看下一致性哈希是如何解决这个问题的。

​ 在一致性哈希算法中，首先将哈希空间映射到一个虚拟的环上，环上的数值分从 0 到 2^32-1（哈希值的范围），如下图：

D2CFEC7D-5ACB-49C3-B67F-12BA52254454.png

在一致性哈希算法刚提出来的时候，32位系统还是主流，2^32-1 相当于最大Integer，现在的应用服务器普遍都是64位系统，在使用使用一致性哈希算法时可以根据实际情况适当变通，比如将哈希值空间放大到 2^64-1。

​ 然后使用同样的哈希算法将缓存服务节点（通常通过服务器IP+端口作为节点的key）和数据键映射到环上的位置。再决定数据落在那台服务器上时，使用一致的方向（比如顺时针方向）沿环查找，遇到的第一个有效服务器就是缓存保存的地方，如图：

7D4C84D6-8843-42FC-AAB4-C5D5EA308C1B.png

